---
title: Risks
layout: post
author: duettmannallison
permalink: /risks/
source-id: 10DhORpdeoLHdygISziFIhZZxLVdwjxT_xFXcQtGDFQ4
published: true
---
# Risks

*"Perhaps the most likely type of existential risks that could constitute a Great Filter are those that arise from technological discovery.  It is not farfetched to suppose that there might be some possible technology which is such that (a) virtually all sufficiently advanced civilizations eventually discover it and (b) its discovery leads almost universally to existential disaster. So where is the Great Filter?  Behind us, or not behind us?" -  Nick Bostrom*

### Readings

Definitions

* [Existential-risk.org](http://www.existential-risk.org/) - good introduction to everything X-risk

* [Existential Risk Resources](https://futureoflife.org/data/documents/Existential%20Risk%20Resources%20(2015-08-24).pdf?x56934) - Bruce Schneider. Comprehensive overview of most sub-topics

* [Existential Risk as Global Priority](http://www.existential-risk.org/concept.html) - Nick Bostrom. Intro to why X-Risks are so extremely important

* [Doomsday Argument](http://www.anthropic-principle.com/?q=anthropic_principle/doomsday_argument) - online paper by Nick Bostrom. An argument from the anthropogenic principle on why doomsday might be close. 

* [The Fermi Paradox](https://waitbutwhy.com/2014/05/fermi-paradox.html) - introductory blog post on WaitButWhy. Possible explanations for why we don't detect any signs from extraterrestrial life, including Drake Equation.

* [Astronomical waste ](https://nickbostrom.com/astronomical/waste.pdf)- online paper by Nick Bostrom. How much value is lost with every minute we don't spend on creating positive futures

* [Confronting Future Catastrophic Risks](http://sethbaum.com/ac/2015_CatastrophicThreats.html) - Seth Baum, Bruce Tonn. Special Futures Issue on Risks

* [Singularity](http://longnow.org/essays/singularity/) - essay by Stewart Brand. Short post warning of the risks of a singularity

* [Top 5 X-risks](https://theconversation.com/the-five-biggest-threats-to-human-existence-27053) - article by Anders Sandberg. From Nuclear war, to nanotech to superintelligence

* [Unknown Unknowns](https://www.scribd.com/doc/18221425/Unknown-unknowns-as-existential-risk-was-UFO-as-Global-Risk) - Alexey Turchin. Article on unknown unknowns as X risk

### Listen & watch

* [S-Risks: Why They Are The Worst X-Risks and How to Prevent Them ](https://www.youtube.com/watch?v=jiZxEJcFExc)- video of EA talk by Max Daniel. Explains how Suffering Risks differ from extinction risks and how to prevent them. 

### Do

* [Future of Humanity Institute](https://www.fhi.ox.ac.uk/) - **Future of Humanity Institute** (**FHI**) is multidisciplinary research institute working on Existential Risk at the University of Oxford.

* [Center for the Study of Existential Risk](http://cser.org/) - The Centre for the Study of Existential Risk is an interdisciplinary research centre within the University of Cambridge dedicated to the study and mitigation of risks that could lead to human extinction or civilisational collapse.

* [Lifeboat Foundation](https://lifeboat.com/) - The Lifeboat Foundation is a nonprofit nongovernmental organization dedicated to encouraging scientific advancements while helping humanity survive [existential risks](https://lifeboat.com/ex/programs) and possible misuse of increasingly powerful technologies, including genetic engineering, nanotechnology, and robotics/AI, as we move towards the [Singularity](http://en.wikipedia.org/wiki/Technological_singularity).

* [Foresight Institute ](https://foresight.org/)- Foresight Institute is a leading non-profit research organization focused on technologies of fundamental importance for the human future, focusing on molecular machine nanotechnology, cybersecurity, and artificial intelligence

* [Future of Life Institute](https://futureoflife.org/) - The Future of Life Institute is a volunteer-run research and outreach organization in the Boston area that works to mitigate existential risks facing humanity, particularly existential risk from advanced artificial intelligence.

* [Global Catastrophic Risk Institute ](http://gcrinstitute.org/)- A think tank leading research, education, and professional networking on global catastrophic risk.

* [John Garrick Institute for the Risk Sciences](https://www.risksciences.ucla.edu/) -  The advancement and application of the risk sciences to save lives, protect the environment and improve system performance. 

* [People for the Ethical Treatment of Reinforcement Learners](http://petrl.org/) - Promoting Moral Consideration for Algorithms

