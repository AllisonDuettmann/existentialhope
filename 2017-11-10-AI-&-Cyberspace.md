---
title: AI & Cyberspace
layout: post
author: duettmannallison
permalink: /ai-&-cyberspace/
source-id: 15maBDKJeG1XwuZVvcUH4WRK_kBUQGFrE1cIUdb44IHw
published: true
---
# AI 

"A great design appears at first insane;But chance will soon seem quaint and blind,And such an exemplary thinking brainWill soon by thinkers be designed" Goethe, 'Faust'

[pretty comprehensive list](https://futureoflife.org/background/benefits-risks-of-artificial-intelligence/) by Future of Life Institute on AI readings and orgs

### Read

Intro

* [The Artificial Intelligence Revolution ](https://waitbutwhy.com/2015/01/artificial-intelligence-revolution-2.html)-  Wait But Why. Introductory post summarizing the potential dangers of Artificial General Intelligence  

* [Life 3.0](https://www.amazon.com/Life-3-0-Being-Artificial-Intelligence/dp/1101946598) - book by Max Tegmark. 

* [Society of Mind](http://www.acad.bg/ebook/ml/Society%20of%20Mind.pdf) - e-book by Marvin Minsky. Alternative definition of AI that highlights a broader understanding of intelligence according to which societies can be intelligent, too

* [EFF AI Metrics ]( https://www.eff.org/ai/metrics)- a useful guide to AI metrics that will be updated regularly

* [AI 100 report](https://ai100.stanford.edu/2016-report) - 100 year study on AI by Stanford

### Risks

* [Superintelligence](https://www.amazon.de/Superintelligence-Dangers-Strategies-Nick-Bostrom/dp/0199678111) - e-book by Nick Bostrom. Classic on Artificial superintellligence, that explores different take-off scenarios of AI, why they're dangerous and urges for preparatory action now.

* [That Alien Message](http://lesswrong.com/lw/qk/that_alien_message/) - Yudkowsky. Challenges mainstream human intuitions on speed of AI.

* [Orthogonality Thesis ](https://wiki.lesswrong.com/wiki/Orthogonality_thesis)- Bostrom, Sandberg, Douglas. Why Intelligence and goals are orthogonal

* [AI as positive and negative factor in Global Risk](http://conferences.asucollegeoflaw.com/sciencepublicsphere/files/2014/02/intelligence.org_files_AIPosNegFactor.pdf) - Eliezer Yudkowsky

* [Roko's Basilisk ](https://rationalwiki.org/wiki/Roko's_basilisk)- Eliezer Yudkowsky

### Strategy & Policy 

* [Unilateralist Curse](https://nickbostrom.com/papers/unilateralist.pdf) - Nick Bostrom. Argues for a principle of conformity amongst groups in the AI space.

* [Guide to working in AI policy](https://80000hours.org/articles/ai-policy-guide/) - Miles Brundage. Lists good orgs one could work for to make a positive difference in AI policy

* [Smart Policies for Artificial Intelligence ](https://arxiv.org/pdf/1608.08196.pdf)- Miles Brundage, Joanna Bryson. 

* [Policy Desiderata in the Development of Machine Superintelligence](https://nickbostrom.com/papers/aipolicy.pdf) - Nick Bostrom, Allan Dafoe, Carrick Flynn. Birds-eye view of policy areas that would be radically affected by AI and recommendations on how to approach policy development

* [Reading Guide for the Global Politics of Artificial Intelligence](http://www.allandafoe.com/aireadings) - comprehensive reading list by Allan Dafoe.

### Ethics

* [Coherent Extrapolated Volition](https://wiki.lesswrong.com/wiki/Coherent_Extrapolated_Volition) - Eliezer Yudkowsky. Good paper to understand why AI safety is hard. His solution CEV is still often cited, even if it is hard to implement in practice.

* [Moral Trade ](http://www.amirrorclear.net/files/moral-trade.pdf)- Toby Ord. Just like trading resources, agents may trade morals. Morality of agents would be more a matter of negotiation than normativity. 

* [Intelligence Distillation](http://www.fhi.ox.ac.uk/wp-content/uploads/MDL-Intelligence-Distillation-for-safe-superintelligent-problem-solving1.pdf) - Eric Drexler. Instead of building a more or less unitary superintelligence, we could attempt to distill advanced intelligence so as to reap the benefits of superintelligence in certain problem domains without having one unitary intelligent entity. 

### AI Alignment

* [AI Alignment: Why it's hard and where to start](https://intelligence.org/2016/12/28/ai-alignment-why-its-hard-and-where-to-start/) - Eliezer Yudkowsky. Even if we knew what we would like an AGI to do, how could we communicate this reliably? 

* [Ensuring Smart-Than-Human Intelligence Has a Positive Outcome](https://intelligence.org/2017/04/12/ensuring/) talk by Nate Soares @Google 

### Listen & Watch

* [Concerning AI](https://concerning.ai/) - Podcast on AI by Ted Sarvata & Brandon Sanders

* [Talking Machines](https://www.thetalkingmachines.com/) - Podcast on AI 

### Do

AI safety orgs

* [Partnership on AI ](https://www.partnershiponai.org/)- Established to study and formulate best practices on AI technologies, to advance the public's understanding of AI, and to serve as an open platform for discussion and engagement about AI and its influences on people and society.Established to study and formulate best practices on AI technologies, to advance the public’s understanding of AI, and to serve as an open platform for discussion and engagement

* [Machine Intelligence Research Institute](https://intelligence.org/) - **MIRI's** artificial intelligence research is focused on developing the mathematical theory of trustworthy reasoning for advanced autonomous AI systems.

* [OpenAI](http://openai.com/) - OpenAI is a non-profit artificial intelligence research company that aims to promote and develop friendly AI in such a way as to benefit humanity as a whole

* [DeepMind](https://deepmind.com/) - AI company, bought by Google. Has strong safety focus

* [Center for Human-Compatible AI](http://humancompatible.ai/) - CHAI's goal is to develop the conceptual and technical wherewithal to reorient the general thrust of AI research towards provably beneficial systems.

* [Leverhulme Centre for the Future of Artificial Intelligence](http://lcfi.ac.uk/) - A global community to ensure that AI benefits all of humanity

* [Center for the Safety and Reliability of Autonomous Systems ](https://www.saras.ucla.edu/)- **SARAS** is an interdisciplinary organization focusing on autonomous system safety and reliability.  

* AI Council on AI & Robotics

SFPL

	Make sure all of San Francisco has access to resources that aren't free by searching for them in our public library’s catalog and suggesting titles if they aren’t available: https://sfpl.org/?pg=2000004401

# Cyberspace

*Governments of the Industrial World, you weary giants of flesh and steel, I come from Cyberspace, the new home of Mind. On behalf of the future, I ask you of the past to leave us alone. You are not welcome among us. You have no sovereignty where we gather. *

* *JPB, Declaration of Independence of Cyberspace*

### Read

Intro

* [Declaration of Independence of Cyberspace](https://www.eff.org/cyberspace-independence) - John Perry Barlow. Speech given by JPB at the World Economic Forum on the properties of cyberspace that make it unlike any other invention.

* [Transparent Society ](http://www.davidbrin.com/transparentsociety.html)- David Brin

* [A Hacker Manifesto](http://meetopia.net/virus/pdf-ps_db/Wark_A-Hacker-Manifesto.pdf) - McKenzie Wark. criticizes the commodification of information in the age of digital culture and globalization

* [The Stack -](https://mitpress.mit.edu/books/stack) Benjamin Bratton. He proposes that different genres of planetary scale computation -smart grids, cloud platforms, mobile apps, smart cities, the Internet of Things, automation- can be seen as forming a coherent whole: an accidental megastructure that is both a computational infrastructure and a new governing architecture. 

Risks

* [Cyber, Nano, and AGI Risk - and Decentralized Approaches to Reduce Risk](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46290.pdf) - Christine Peterson, Mark Miller, Allison Duettmann. Cybersecurity as near-term, undervalued catastrophic risk that is more imminent than risk from AGI and potential solutions.

* [AI and Cyber security](https://arxiv.org/abs/1610.07997) - Roman Yampolskiy. Cybersecurity approaches for AI safety

* Cyber Insurance - Sandberg, Petratos, Zhou. Book chapter to be published soon on which cyber risks could be insured.

Simulation Argument

* [FAQ on Simulation Argument](https://www.simulation-argument.com/faq.html) - Nick Bostrom answers questions on his often wildly misinterpreted simulation argument

### Do

* [Electronic Frontier Foundation](https://www.eff.org/) - The **Electronic Frontier Foundation** (**EFF**) is an international non-profit digital rights group based in San Francisco, California. 

* [Data & Society](https://datasociety.net/) - Data & Society is a research institute focused on the social and cultural issues arising from data-centric technological development.

* [Internet Archive](https://archive.org/) - Internet Archive is a non-profit library of millions of free books, movies, software, music, websites, and more.

